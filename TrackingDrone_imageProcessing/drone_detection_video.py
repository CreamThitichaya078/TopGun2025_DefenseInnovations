import cv2
import numpy as np
import pandas as pd
from ultralytics import YOLO
import joblib
from pathlib import Path

# ‡πÄ‡∏õ‡πá‡∏ô‡πÇ‡∏Ñ‡∏£‡∏á‡∏´‡∏•‡∏±‡∏Å‡∏Ç‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡∏£‡∏ß‡∏°‡∏ó‡∏∏‡∏Å‡πÇ‡∏°‡∏î‡∏π‡∏•‡πÄ‡∏Ç‡πâ‡∏≤‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô
class DroneTrackingSystem:
    """
    ‡∏£‡∏∞‡∏ö‡∏ö‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡πÅ‡∏•‡∏∞‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏û‡∏¥‡∏Å‡∏±‡∏î‡πÇ‡∏î‡∏£‡∏ô‡πÅ‡∏ö‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏•‡πÑ‡∏ó‡∏°‡πå
    ‡∏£‡∏ß‡∏°‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö (YOLO), ‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏° (BYTETracker), ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏û‡∏¥‡∏Å‡∏±‡∏î (XGBoost)
    ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡πÅ‡∏ö‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏•‡πÑ‡∏ó‡∏°‡πå‡∏ö‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠
    """
    # ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• YOLO (detect + track) ‡πÅ‡∏•‡∏∞ XGBoost (predict coordinate)
    def __init__(self, yolo_model_path, xgb_model_path):
        """
        ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö‡πÇ‡∏î‡∏¢‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏™‡∏≠‡∏á

        Parameters:
        - yolo_model_path: path ‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡πÑ‡∏ü‡∏•‡πå .pt ‡∏Ç‡∏≠‡∏á YOLOv8n ‡∏ó‡∏µ‡πà train ‡πÅ‡∏•‡πâ‡∏ß
        - xgb_model_path: path ‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡πÑ‡∏ü‡∏•‡πå .joblib ‡∏Ç‡∏≠‡∏á XGBoost
        """
        self.yolo_model = YOLO(yolo_model_path)
        self.xgb_model = joblib.load(xgb_model_path)
        self.track_colors = {}
        self.tracks_path = {}

        print("‚úì ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß")
    # ‡∏™‡∏∏‡πà‡∏°‡∏™‡∏µ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞ track_id
    def get_track_color(self, track_id):
        """
        ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏´‡∏£‡∏∑‡∏≠‡∏î‡∏∂‡∏á‡∏™‡∏µ‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÉ‡∏´‡πâ‡∏Å‡∏±‡∏ö track_id ‡∏ô‡∏±‡πâ‡∏ô‡πÜ
        ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÇ‡∏î‡∏£‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏•‡∏≥‡∏°‡∏µ‡∏™‡∏µ‡∏ó‡∏µ‡πà‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô‡πÅ‡∏•‡∏∞‡∏Ñ‡∏á‡∏ó‡∏µ‡πà‡∏ï‡∏•‡∏≠‡∏î‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠
        """
        if track_id not in self.track_colors:
            np.random.seed(int(track_id))
            color = tuple(map(int, np.random.randint(50, 255, 3)))
            self.track_colors[track_id] = color
        return self.track_colors[track_id]
    # ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏û‡∏¥‡∏Å‡∏±‡∏î‡∏à‡∏≤‡∏Å bounding box ‡∏ó‡∏µ‡πà YOLO ‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö
    def predict_coordinates(self, detections_df):
        """
        ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏û‡∏¥‡∏Å‡∏±‡∏î (lat, lon, alt) ‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö

        Parameters:
        - detections_df: DataFrame ‡∏ó‡∏µ‡πà‡∏°‡∏µ columns: center_x, center_y, width, height

        Returns:
        - DataFrame ‡∏ó‡∏µ‡πà‡∏°‡∏µ columns: Latitude, Longitude, Altitude
        """
        if len(detections_df) == 0:
            return pd.DataFrame(columns=['Latitude', 'Longitude', 'Altitude'])

        features = detections_df[['center_x', 'center_y', 'width', 'height']]
        predictions = self.xgb_model.predict(features)
        coords_df = pd.DataFrame(predictions, columns=['Latitude', 'Longitude', 'Altitude'])

        return coords_df
    # ‡πÅ‡∏™‡∏î‡∏á ‡πÅ‡∏ú‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡πâ‡∏≤‡∏ô‡∏Ç‡∏ß‡∏≤‡∏ö‡∏ô ‡∏Ç‡∏≠‡∏á‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠ ‡πÄ‡∏ä‡πà‡∏ô
    # Frame ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô
    # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÇ‡∏î‡∏£‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö
    # FPS (frame per second)
    # ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞ paused
    def draw_info_panel(self, frame, frame_count, total_frames, num_drones, fps_display, paused=False):
        """
        ‡∏ß‡∏≤‡∏î‡πÅ‡∏ú‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏∏‡∏°‡∏ö‡∏ô‡∏Ç‡∏ß‡∏≤‡∏Ç‡∏≠‡∏á‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡∏Ç‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏ö

        Parameters:
        - frame: ‡πÄ‡∏ü‡∏£‡∏°‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ß‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡∏á‡πÑ‡∏õ
        - frame_count: ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏•‡∏Ç‡πÄ‡∏ü‡∏£‡∏°‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô
        - total_frames: ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏ü‡∏£‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
        - num_drones: ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÇ‡∏î‡∏£‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡πÉ‡∏ô‡πÄ‡∏ü‡∏£‡∏°‡∏ô‡∏µ‡πâ
        - fps_display: ‡∏Ñ‡πà‡∏≤ FPS ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏à‡∏£‡∏¥‡∏á
        - paused: ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏≤‡∏£‡∏´‡∏¢‡∏∏‡∏î‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß
        """
        height, width = frame.shape[:2]

        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ú‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        panel_height = 120
        overlay = frame.copy()
        cv2.rectangle(overlay, (width - 300, 0), (width, panel_height), (0, 0, 0), -1)
        cv2.addWeighted(overlay, 0.6, frame, 0.4, 0, frame)

        # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÅ‡∏™‡∏î‡∏á
        font = cv2.FONT_HERSHEY_SIMPLEX
        font_scale = 0.6
        thickness = 2
        y_offset = 25

        # ‡πÅ‡∏™‡∏î‡∏á‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏•‡∏Ç‡πÄ‡∏ü‡∏£‡∏°
        progress = (frame_count / total_frames) * 100 if total_frames > 0 else 0
        frame_text = f"Frame: {frame_count}/{total_frames} ({progress:.1f}%)"
        cv2.putText(frame, frame_text, (width - 290, y_offset),
                    font, font_scale, (255, 255, 255), thickness)

        # ‡πÅ‡∏™‡∏î‡∏á‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÇ‡∏î‡∏£‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö
        y_offset += 30
        drone_text = f"Drones: {num_drones}"
        color = (0, 255, 0) if num_drones > 0 else (128, 128, 128)
        cv2.putText(frame, drone_text, (width - 290, y_offset),
                    font, font_scale, color, thickness)

        # ‡πÅ‡∏™‡∏î‡∏á FPS ‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏î‡πâ‡∏à‡∏£‡∏¥‡∏á
        y_offset += 30
        fps_text = f"FPS: {fps_display:.1f}"
        cv2.putText(frame, fps_text, (width - 290, y_offset),
                    font, font_scale, (255, 255, 0), thickness)

        # ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏≤‡∏£‡∏´‡∏¢‡∏∏‡∏î‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß
        if paused:
            y_offset += 30
            cv2.putText(frame, "PAUSED", (width - 290, y_offset),
                        font, font_scale, (0, 0, 255), thickness)

        return frame

    # ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏° ‡∏ó‡∏µ‡πà‡∏°‡∏∏‡∏°‡∏•‡πà‡∏≤‡∏á‡∏ã‡πâ‡∏≤‡∏¢
    def draw_instructions(self, frame):
        """
        ‡∏ß‡∏≤‡∏î‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏°‡∏∏‡∏°‡∏•‡πà‡∏≤‡∏á‡∏ã‡πâ‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠
        ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏ó‡∏£‡∏≤‡∏ö‡∏ß‡πà‡∏≤‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Å‡∏î‡∏õ‡∏∏‡πà‡∏°‡∏≠‡∏∞‡πÑ‡∏£‡πÑ‡∏î‡πâ‡∏ö‡πâ‡∏≤‡∏á
        """
        instructions = [
            "Controls:",
            "SPACE - Pause/Resume",
            "Q/ESC - Quit",
            "S - Save current frame"
        ]

        font = cv2.FONT_HERSHEY_SIMPLEX
        font_scale = 0.5
        thickness = 1
        y_start = frame.shape[0] - 100

        # ‡∏ß‡∏≤‡∏î‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á‡πÇ‡∏õ‡∏£‡πà‡∏á‡πÅ‡∏™‡∏á
        overlay = frame.copy()
        cv2.rectangle(overlay, (10, y_start - 25), (250, frame.shape[0] - 10), (0, 0, 0), -1)
        cv2.addWeighted(overlay, 0.6, frame, 0.4, 0, frame)

        # ‡∏ß‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡∏•‡∏∞‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î
        for i, instruction in enumerate(instructions):
            y_position = y_start + (i * 20)
            cv2.putText(frame, instruction, (15, y_position),
                        font, font_scale, (255, 255, 255), thickness)

        return frame
    # ‡πÄ‡∏õ‡πá‡∏ô ‚Äú‡∏´‡∏±‡∏ß‡πÉ‡∏à‚Äù ‡∏Ç‡∏≠‡∏á‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏° ‚Äî ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Å‡∏±‡∏ö‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏ó‡∏µ‡∏•‡∏∞‡πÄ‡∏ü‡∏£‡∏°
    def process_video(self, video_path, output_path, conf_threshold=0.01, show_display=True,
                      display_scale=1.0, save_frames=False):
        """
        ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏ó‡∏µ‡∏•‡∏∞‡πÄ‡∏ü‡∏£‡∏° ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡πÅ‡∏•‡∏∞‡∏û‡∏¥‡∏Å‡∏±‡∏î‡πÅ‡∏ö‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏•‡πÑ‡∏ó‡∏°‡πå

        Parameters:
        - video_path: path ‡∏Ç‡∏≠‡∏á‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏≠‡∏¥‡∏ô‡∏û‡∏∏‡∏ï
        - output_path: path ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
        - conf_threshold: ‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö (0-1)
        - show_display: ‡πÅ‡∏™‡∏î‡∏á‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡πà‡∏≤‡∏á‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        - display_scale: ‡∏Ç‡∏ô‡∏≤‡∏î‡∏Ç‡∏≠‡∏á‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡πà‡∏≤‡∏á‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏• (1.0 = ‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏ï‡πá‡∏°, 0.5 = ‡∏Ñ‡∏£‡∏∂‡πà‡∏á‡∏´‡∏ô‡∏∂‡πà‡∏á)
        - save_frames: ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏ü‡∏£‡∏°‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÄ‡∏ü‡∏£‡∏°‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏†‡∏≤‡∏û‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        """
        # ‡πÄ‡∏õ‡∏¥‡∏î‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠
        cap = cv2.VideoCapture(video_path)

        if not cap.isOpened():
            raise ValueError(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏õ‡∏¥‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠: {video_path}")

        # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠
        fps = int(cap.get(cv2.CAP_PROP_FPS))
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

        print(f"\nüìπ ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠:")
        print(f"   - ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î: {width}x{height}")
        print(f"   - FPS: {fps}")
        print(f"   - ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏ü‡∏£‡∏°: {total_frames}")
        print(f"   - ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß: {total_frames / fps:.2f} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ")

        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏≠‡∏±‡∏û‡∏û‡∏∏‡∏ï
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))

        # ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô
        frame_count = 0
        paused = False

        # ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì FPS ‡∏à‡∏£‡∏¥‡∏á
        import time
        fps_start_time = time.time()
        fps_frame_count = 0
        fps_display = 0

        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡πà‡∏≤‡∏á‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
        if show_display:
            window_name = "Drone Tracking System - Real-time View"
            cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)

            # ‡∏õ‡∏£‡∏±‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡πà‡∏≤‡∏á‡∏ï‡∏≤‡∏° scale ‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î
            display_width = int(width * display_scale)
            display_height = int(height * display_scale)
            cv2.resizeWindow(window_name, display_width, display_height)

        print(f"\nüöÅ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠...")
        if show_display:
            print(f"   üí° ‡∏Å‡∏î SPACE ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏¢‡∏∏‡∏î‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß, Q ‡∏´‡∏£‡∏∑‡∏≠ ESC ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏≠‡∏Å, S ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏ü‡∏£‡∏°‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô")

        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏ü‡∏£‡∏° (‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£)
        if save_frames:
            frames_dir = Path("saved_frames")
            frames_dir.mkdir(exist_ok=True)

        while True:
            # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏´‡∏¢‡∏∏‡∏î‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß ‡πÉ‡∏´‡πâ‡∏≠‡πà‡∏≤‡∏ô‡πÄ‡∏ü‡∏£‡∏°‡πÉ‡∏´‡∏°‡πà
            if not paused:
                ret, frame = cap.read()
                if not ret:
                    break

                frame_count += 1
                fps_frame_count += 1

                # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì FPS ‡∏à‡∏£‡∏¥‡∏á‡∏ó‡∏∏‡∏Å‡πÜ 30 ‡πÄ‡∏ü‡∏£‡∏°
                if fps_frame_count >= 30:
                    fps_end_time = time.time()
                    fps_display = fps_frame_count / (fps_end_time - fps_start_time)
                    fps_start_time = time.time()
                    fps_frame_count = 0

                # ‡πÉ‡∏ä‡πâ YOLO ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÅ‡∏•‡∏∞‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡πÇ‡∏î‡∏£‡∏ô‡∏î‡πâ‡∏ß‡∏¢ BYTETracker
                results = self.yolo_model.track(
                    frame,
                    persist=True,
                    conf=conf_threshold,
                    iou=0.25,
                    tracker="bytetrack.yaml",
                    verbose=False  # ‡∏õ‡∏¥‡∏î‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å YOLO
                )

                # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö
                detections = []

                if results[0].boxes is not None and results[0].boxes.id is not None:
                    boxes = results[0].boxes.xywh.cpu().numpy()
                    track_ids = results[0].boxes.id.cpu().numpy().astype(int)
                    confidences = results[0].boxes.conf.cpu().numpy()

                    for box, track_id, conf in zip(boxes, track_ids, confidences):
                        center_x, center_y, w, h = box

                        # ‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡πà‡∏≤‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô normalized coordinates
                        center_x_norm = center_x / width
                        center_y_norm = center_y / height
                        w_norm = w / width
                        h_norm = h / height

                        detections.append({
                            'track_id': track_id,
                            'center_x': center_x_norm,
                            'center_y': center_y_norm,
                            'width': w_norm,
                            'height': h_norm,
                            'center_x_pixel': center_x,
                            'center_y_pixel': center_y,
                            'w_pixel': w,
                            'h_pixel': h,
                            'confidence': conf
                        })



                # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏ü‡∏£‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•
                display_frame = frame.copy()

                # --- ‡∏ß‡∏≤‡∏î‡πÄ‡∏™‡πâ‡∏ô tracking ---
                for det in detections:
                    track_id = det['track_id']
                    cx, cy = det['center_x_pixel'], det['center_y_pixel']

                    if track_id not in self.tracks_path:
                        self.tracks_path[track_id] = []
                    self.tracks_path[track_id].append((cx, cy))
                    if len(self.tracks_path[track_id]) > 50:  # ‡πÄ‡∏Å‡πá‡∏ö 50 ‡∏à‡∏∏‡∏î‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
                        self.tracks_path[track_id].pop(0)

                for tid, points in self.tracks_path.items():
                    color = self.get_track_color(tid)
                    for i in range(1, len(points)):
                        if points[i - 1] is None or points[i] is None:
                            continue
                        cv2.line(display_frame, points[i - 1], points[i], color, 2)

                # ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡πÇ‡∏î‡∏£‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö ‡πÉ‡∏´‡πâ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏û‡∏¥‡∏Å‡∏±‡∏î‡πÅ‡∏•‡∏∞‡∏ß‡∏≤‡∏î‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
                if len(detections) > 0:
                    detections_df = pd.DataFrame(detections)
                    coords_df = self.predict_coordinates(
                        detections_df[['center_x', 'center_y', 'width', 'height']]
                    )

                    # ‡∏ß‡∏≤‡∏î‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ö‡∏ô‡πÄ‡∏ü‡∏£‡∏°
                    for idx, det in enumerate(detections):
                        track_id = det['track_id']

                        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏°‡∏∏‡∏°‡∏Ç‡∏≠‡∏á bounding box
                        x1 = int(det['center_x_pixel'] - det['w_pixel'] / 2)
                        y1 = int(det['center_y_pixel'] - det['h_pixel'] / 2)
                        x2 = int(det['center_x_pixel'] + det['w_pixel'] / 2)
                        y2 = int(det['center_y_pixel'] + det['h_pixel'] / 2)

                        # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏™‡∏µ‡∏ï‡∏≤‡∏° track_id
                        color = self.get_track_color(track_id)

                        # ‡∏ß‡∏≤‡∏î‡∏Å‡∏£‡∏≠‡∏ö‡∏™‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏µ‡πà‡∏¢‡∏° (‡∏´‡∏ô‡∏≤‡∏Ç‡∏∂‡πâ‡∏ô‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÄ‡∏´‡πá‡∏ô‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô)
                        cv2.rectangle(display_frame, (x1, y1), (x2, y2), color, 3)

                        # ‡∏î‡∏∂‡∏á‡∏û‡∏¥‡∏Å‡∏±‡∏î‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡πÑ‡∏î‡πâ
                        lat = coords_df.iloc[idx]['Latitude']
                        lon = coords_df.iloc[idx]['Longitude']
                        alt = coords_df.iloc[idx]['Altitude']
                        conf = det['confidence']

                        # ‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
                        label_id = f"ID: {track_id} ({conf:.2f})"
                        label_coords = f"Lat: {lat:.6f}"
                        label_lon = f"Lon: {lon:.6f}"
                        label_alt = f"Alt: {alt:.2f}m"

                        # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏ü‡∏≠‡∏ô‡∏ï‡πå
                        font = cv2.FONT_HERSHEY_SIMPLEX
                        font_scale = 0.6
                        thickness = 2

                        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ç‡∏ô‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á
                        labels = [label_id, label_coords, label_lon, label_alt]
                        max_width = 0
                        line_height = 0

                        for label in labels:
                            (w_text, h_text), _ = cv2.getTextSize(label, font, font_scale, thickness)
                            max_width = max(max_width, w_text)
                            line_height = max(line_height, h_text)

                        # ‡∏ß‡∏≤‡∏î‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
                        padding = 5
                        text_y_start = y1 - (len(labels) * (line_height + padding)) - padding

                        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÑ‡∏°‡πà‡∏•‡πâ‡∏ô‡∏≠‡∏≠‡∏Å‡∏ô‡∏≠‡∏Å‡πÄ‡∏ü‡∏£‡∏°
                        if text_y_start < 0:
                            text_y_start = y2 + padding

                        overlay = display_frame.copy()
                        cv2.rectangle(overlay,
                                      (x1, text_y_start),
                                      (x1 + max_width + (padding * 2),
                                       text_y_start + (len(labels) * (line_height + padding)) + padding),
                                      (0, 0, 0), -1)
                        cv2.addWeighted(overlay, 0.7, display_frame, 0.3, 0, display_frame)

                        # ‡∏ß‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡∏•‡∏∞‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î
                        current_y = text_y_start + line_height + padding
                        for i, label in enumerate(labels):
                            text_color = color if i == 0 else (255, 255, 255)
                            cv2.putText(display_frame, label, (x1 + padding, current_y),
                                        font, font_scale, text_color, thickness)
                            current_y += line_height + padding

                # ‡∏ß‡∏≤‡∏î‡πÅ‡∏ú‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥
                display_frame = self.draw_info_panel(display_frame, frame_count, total_frames,
                                                     len(detections), fps_display, paused)
                if show_display:
                    display_frame = self.draw_instructions(display_frame)

                # ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÄ‡∏ü‡∏£‡∏°‡∏•‡∏á‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠
                out.write(display_frame)

            # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏ö‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠
            if show_display:
                cv2.imshow(window_name, display_frame)

                # ‡∏£‡∏≠‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏à‡∏≤‡∏Å‡πÅ‡∏õ‡πâ‡∏ô‡∏û‡∏¥‡∏°‡∏û‡πå
                key = cv2.waitKey(1 if not paused else 0) & 0xFF

                # ‡∏Å‡∏î SPACE ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏¢‡∏∏‡∏î‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏•‡πà‡∏ô‡∏ï‡πà‡∏≠
                if key == ord(' '):
                    paused = not paused
                    if paused:
                        print(f"\n‚è∏Ô∏è  ‡∏´‡∏¢‡∏∏‡∏î‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß‡∏ó‡∏µ‡πà‡πÄ‡∏ü‡∏£‡∏° {frame_count}")
                    else:
                        print(f"‚ñ∂Ô∏è  ‡πÄ‡∏•‡πà‡∏ô‡∏ï‡πà‡∏≠‡∏à‡∏≤‡∏Å‡πÄ‡∏ü‡∏£‡∏° {frame_count}")
                        fps_start_time = time.time()  # ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï‡∏ï‡∏±‡∏ß‡∏ô‡∏±‡∏ö FPS
                        fps_frame_count = 0

                # ‡∏Å‡∏î Q ‡∏´‡∏£‡∏∑‡∏≠ ESC ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°
                elif key == ord('q') or key == 27:
                    print(f"\n‚èπÔ∏è  ‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏ü‡∏£‡∏° {frame_count}")
                    break

                # ‡∏Å‡∏î S ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏ü‡∏£‡∏°‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô
                elif key == ord('s') and save_frames:
                    save_path = frames_dir / f"frame_{frame_count:06d}.jpg"
                    cv2.imwrite(str(save_path), display_frame)
                    print(f"üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏ü‡∏£‡∏°‡πÑ‡∏ß‡πâ‡∏ó‡∏µ‡πà: {save_path}")

            # ‡πÅ‡∏™‡∏î‡∏á progress ‡∏ó‡∏∏‡∏Å‡πÜ 30 ‡πÄ‡∏ü‡∏£‡∏°
            if not paused and frame_count % 30 == 0:
                progress = (frame_count / total_frames) * 100
                print(f"   ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏∑‡∏ö‡∏´‡∏ô‡πâ‡∏≤: {progress:.1f}% ({frame_count}/{total_frames} ‡πÄ‡∏ü‡∏£‡∏°) | FPS: {fps_display:.1f}")

        # ‡∏õ‡∏¥‡∏î‡∏ó‡∏∏‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á
        cap.release()
        out.release()

        if show_display:
            cv2.destroyAllWindows()

        print(f"\n‚úÖ ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô! ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡πÑ‡∏ß‡πâ‡∏ó‡∏µ‡πà: {output_path}")
        print(f"   ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î {frame_count} ‡πÄ‡∏ü‡∏£‡∏°")
        print(f"   ‡πÄ‡∏ß‡∏•‡∏≤‡∏£‡∏ß‡∏°: {(frame_count / fps):.2f} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ")


# ==================== ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô ====================

if __name__ == "__main__":
    # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î paths ‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠
    YOLO_MODEL_PATH = "best (Punch).pt"
    XGB_MODEL_PATH = "XGB_model.joblib"
    INPUT_VIDEO = "P3_VIDEO.mp4"
    OUTPUT_VIDEO = "output_tracked_video.mp4"

    try:
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏∞‡∏ö‡∏ö‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡πÇ‡∏î‡∏£‡∏ô
        system = DroneTrackingSystem(YOLO_MODEL_PATH, XGB_MODEL_PATH)

        # ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡πÅ‡∏ö‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏•‡πÑ‡∏ó‡∏°‡πå
        system.process_video(
            video_path=INPUT_VIDEO,
            output_path=OUTPUT_VIDEO,
            conf_threshold=0.01,
            show_display=True,  # ‡πÄ‡∏õ‡∏¥‡∏î‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡πÅ‡∏ö‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏•‡πÑ‡∏ó‡∏°‡πå
            display_scale=0.8,  # ‡∏õ‡∏£‡∏±‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡πà‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô 80% ‡∏Ç‡∏≠‡∏á‡∏Ç‡∏ô‡∏≤‡∏î‡∏à‡∏£‡∏¥‡∏á
            save_frames=True  # ‡πÄ‡∏õ‡∏¥‡∏î‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏ü‡∏£‡∏°‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏Å‡∏î S
        )

    except Exception as e:
        print(f"\n‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {str(e)}")
        import traceback

        traceback.print_exc()